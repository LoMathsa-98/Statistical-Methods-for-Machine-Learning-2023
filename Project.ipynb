{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767f5f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### IMPORT LIBRARY\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Regression import RidgeRegression\n",
    "\n",
    "#IMPORT DATA\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 8)\n",
    "\n",
    "# NaN CONTROL\n",
    "print (dataset.isna().sum().sort_values(ascending = False))\n",
    "dataset[dataset.isna().any(axis=1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d52ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLEANING DATA: Shifting + normalizing\n",
    "dataset['Explicit'] = dataset['explicit'].astype(int)\n",
    "dataset = dataset.drop('explicit',axis = 1)\n",
    "dataset['Major'] = dataset['mode'].astype(int)\n",
    "dataset = dataset.drop('mode',axis = 1)\n",
    "# SHIFTING loudness\n",
    "min_value = dataset['loudness'].min()\n",
    "dataset['loudness'] = dataset['loudness'] - min_value\n",
    "# NORMALIZING  loudness + tempo + duration_ms (there are outliers...) \n",
    "max_value_shifted = dataset['loudness'].max()\n",
    "dataset['loudness'] = dataset['loudness'] / max_value_shifted\n",
    "max_value_shifted = dataset['duration_ms'].max()\n",
    "dataset['duration_ms'] = dataset['duration_ms'] / max_value_shifted\n",
    "max_value_shifted = dataset['tempo'].max()\n",
    "dataset['tempo'] = dataset['tempo'] / max_value_shifted\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ONE-HOT ENCODER - GENRE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse = False, drop='first')\n",
    "\n",
    "encoded_genre = encoder.fit_transform(dataset[['track_genre']])\n",
    "encoded_genre_df = pd.DataFrame(encoded_genre, columns=encoder.get_feature_names_out(['track_genre']))\n",
    "encoded_genre_df.index = dataset['Unnamed: 0']\n",
    "\n",
    "dataset_encoded = pd.concat([dataset.drop('track_genre', axis=1), encoded_genre_df], axis=1) # maybe change name\n",
    "\n",
    "#### OHE - KEY+TIME\n",
    "encoded_tsign = encoder.fit_transform(dataset[['time_signature']])\n",
    "encoded_tsign_df = pd.DataFrame(encoded_tsign, columns=encoder.get_feature_names_out(['time_signature']))\n",
    "\n",
    "encoded_key = encoder.fit_transform(dataset[['key']])\n",
    "encoded_key_df = pd.DataFrame(encoded_key, columns=encoder.get_feature_names_out(['key']))\n",
    "\n",
    "encoded_key_df.index = dataset['Unnamed: 0']\n",
    "encoded_tsign_df.index = dataset['Unnamed: 0']\n",
    "\n",
    "dataset_encoded2 = pd.concat([dataset.drop('time_signature', axis=1), encoded_tsign_df], axis=1)\n",
    "dataset_encoded2 = pd.concat([dataset_encoded2.drop('key', axis=1), encoded_key_df], axis=1)\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original DataFrame\n",
    "dataset_encoded3 = pd.concat([dataset.drop('key', axis=1), encoded_key_df], axis=1)\n",
    "\n",
    "\n",
    "## TRAIN-VALIDATION-TEST SET\n",
    "\n",
    "# NUMERIC - no  aggr\n",
    "numeric_df = dataset.select_dtypes(include=['int', 'float']).drop(['time_signature', 'key', 'Unnamed: 0'], axis = 1) # Numeric cloumns\n",
    "# NUMERIC - aggr\n",
    "df_aggr_no_genre = dataset.groupby('track_id').agg('first').sort_values(by='Unnamed: 0') \n",
    "numeric_df_aggr = df_aggr_no_genre.select_dtypes(include=['int', 'float']).drop(['time_signature', 'key', 'Unnamed: 0'], axis = 1)\n",
    "\n",
    "## OHE GENRE - NO AGGREGATION\n",
    "genre_df = dataset_encoded.select_dtypes(include=['int', 'float','uint8']).drop(['time_signature', 'key', 'Unnamed: 0'], axis = 1)\n",
    "\n",
    "\n",
    "#### OHE - AGGREGATION with genre 0-1\n",
    "genre_columns = dataset_encoded.select_dtypes(include=['uint8']).columns.to_list()\n",
    "other_columns = dataset_encoded.select_dtypes(include=['int', 'float','object','bool']).columns.to_list()  # numeric\n",
    "\n",
    "## AGGREGATION FUNCTIONS\n",
    "aggregation_functions_g = {}\n",
    "for col in dataset_encoded.columns:\n",
    "    if col in other_columns:\n",
    "        aggregation_functions_g[col] = 'first'\n",
    "    elif col in genre_columns:\n",
    "        aggregation_functions_g[col] = 'max'\n",
    "\n",
    "genre_df_aggr = dataset_encoded.groupby('track_id').agg(aggregation_functions_g).sort_values(by='Unnamed: 0')\n",
    "\n",
    "# CATEGORICAL DATA [sum of genres = 1]\n",
    "genre_df_aggr = genre_df_aggr.select_dtypes(include=['int', 'float','uint8']).drop(['time_signature', 'key', 'Unnamed: 0'], axis = 1)\n",
    "\n",
    "## OHE other - NO AGGREGATION\n",
    "KT_df = dataset_encoded2.select_dtypes(include=['int', 'float','uint8']).drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "## OHE other - AGGREGATION\n",
    "KT_df_aggr = df_aggr_no_genre.select_dtypes(include=['int', 'float','uint8']).drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "## COLUMN - OHE other - NO AGGREGATION\n",
    "K_df = dataset_encoded3.select_dtypes(include=['int', 'float','uint8']).drop(['time_signature', 'Unnamed: 0'], axis = 1)\n",
    "\n",
    "K_df_aggr = df_aggr_no_genre.select_dtypes(include=['int', 'float','uint8']).drop(['time_signature', 'Unnamed: 0'], axis = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c9ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## 1st dataset - num not aggregated\n",
    "X = numeric_df.drop('popularity',axis = 1).values\n",
    "y = numeric_df['popularity'].values \n",
    "# 2nd dataset - num aggregated\n",
    "X_2 = numeric_df_aggr.drop('popularity',axis = 1).values\n",
    "y_2 = numeric_df_aggr['popularity'].values\n",
    "## 3rd - ohe genre no aggregated\n",
    "X_3 = genre_df.drop('popularity', axis = 1).values\n",
    "y_3 = genre_df['popularity'].values\n",
    "## 4th dataset - ohe genre aggregated \n",
    "X_4 = genre_df_aggr.drop('popularity', axis = 1).values\n",
    "y_4 = genre_df_aggr['popularity'].values\n",
    "## 5th dataset - ohe key+time_sign not aggregated\n",
    "X_5 = KT_df.drop('popularity',axis = 1).values\n",
    "y_5 = KT_df['popularity'].values\n",
    "## 6th dataset - ohe key+time_sign aggregated\n",
    "X_6 = KT_df_aggr.drop('popularity',axis = 1).values\n",
    "y_6 = KT_df_aggr['popularity'].values\n",
    "## 7th dataset - ohe key not aggregated\n",
    "X_7 = K_df.drop('popularity',axis = 1).values  # Convert selected columns to numpy array\n",
    "y_7 = K_df['popularity'].values\n",
    "## 8th dataset - ohe key aggregated\n",
    "X_8 = K_df_aggr.drop('popularity',axis = 1).values\n",
    "y_8 = K_df_aggr['popularity'].values\n",
    "\n",
    "# SPLIT the dataset into train and test sets (70% train, 30% test) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2, y_2, test_size=0.30, random_state=42)\n",
    "X_3_train, X_3_test, y_3_train, y_3_test = train_test_split(X_3, y_3, test_size=0.30, random_state=42)\n",
    "X_4_train, X_4_test, y_4_train, y_4_test = train_test_split(X_4, y_4, test_size=0.30, random_state=42)\n",
    "X_5_train, X_5_test, y_5_train, y_5_test = train_test_split(X_5, y_5, test_size=0.30, random_state=42)\n",
    "X_6_train, X_6_test, y_6_train, y_6_test = train_test_split(X_6, y_6, test_size=0.30, random_state=42)\n",
    "X_7_train, X_7_test, y_7_train, y_7_test = train_test_split(X_7, y_7, test_size=0.30, random_state=42)\n",
    "X_8_train, X_8_test, y_8_train, y_8_test = train_test_split(X_8, y_8, test_size=0.30, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "## 1st REGRESSION\n",
    "model = RidgeRegression(reg_param=1.5) \n",
    "betas_1 = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "#print(\"Betas 1 [numeric features - not aggregation]:\", betas_1)\n",
    "print(\"Predictions 1 [numeric features - not aggregation]:\", y_pred)\n",
    "\n",
    "## 2nd REGRESSION\n",
    "model = RidgeRegression(reg_param=1.5) \n",
    "betas_2 = model.fit(X_2_train, y_2_train)\n",
    "y_pred_2 = model.predict(X_2_test)\n",
    "#print(\"Betas 2 [numeric features - aggregation]:\", betas_2)\n",
    "print(\"Predictions 2 [numeric features - aggregation]:\", y_pred_2)\n",
    "\n",
    "# 3rd REGRESSION\n",
    "model = RidgeRegression(reg_param=1.5)\n",
    "betas_3 = model.fit(X_3_train, y_3_train)\n",
    "y_pred_3 = model.predict(X_3_test)\n",
    "#print(\"Betas 3 [numeric + genre features - not aggregation]:\", betas_3)\n",
    "print(\"Predictions 3 [numeric features + genre features - not aggregation]:\", y_pred_3)\n",
    "\n",
    "## 4th - REGRESSION\n",
    "model = RidgeRegression(reg_param=1.5)\n",
    "betas_4 = model.fit(X_4_train, y_4_train)\n",
    "y_pred_4 = model.predict(X_4_test)\n",
    "#print(\"Betas 4 [numeric + genre features - aggregation]:\", betas_4)\n",
    "print(\"Predictions 4 [numeric features + genre - aggregation]:\", y_pred_4)\n",
    "\n",
    "## 5th - REGRESSION\n",
    "model = RidgeRegression(reg_param=1.5)\n",
    "betas_5 = model.fit(X_5_train, y_5_train)\n",
    "y_pred_5 = model.predict(X_5_test)\n",
    "print(\"Predictions 5 [numeric features + key and time signature - no aggregation]:\", y_pred_5)\n",
    "\n",
    "## 6th - REGRESSION\n",
    "model = RidgeRegression(reg_param=1.5)\n",
    "betas_6 = model.fit(X_6_train, y_6_train)\n",
    "y_pred_6 = model.predict(X_6_test)\n",
    "#print(\"Betas 6:\", betas_6)\n",
    "print(\"Predictions 6: [numeric features + key and time signature - aggregation]\", y_pred_6)\n",
    "\n",
    "## 7th - REGRESSION\n",
    "model = RidgeRegression(reg_param=1.5)\n",
    "betas_7 = model.fit(X_7_train, y_7_train)\n",
    "y_pred_7 = model.predict(X_7_test)\n",
    "print(\"Predictions 7 [numeric features + key - no aggregation]:\", y_pred_7)\n",
    "\n",
    "## 8th - REGRESSION\n",
    "model = RidgeRegression(reg_param=1.5)\n",
    "betas_8 = model.fit(X_8_train, y_8_train)\n",
    "y_pred_8 = model.predict(X_8_test)\n",
    "#print(\"Betas 8:\", betas_8)\n",
    "print(\"Predictions 8 [numeric features + key - no aggregation]:\", y_pred_8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse_2 = mean_squared_error(y_2_test, y_pred_2)\n",
    "mse_3 = mean_squared_error(y_3_test, y_pred_3)\n",
    "mse_5 = mean_squared_error(y_5_test, y_pred_5)\n",
    "mse_4 = mean_squared_error(y_4_test, y_pred_4)\n",
    "mse_6 = mean_squared_error(y_6_test, y_pred_6)\n",
    "mse_7 = mean_squared_error(y_7_test, y_pred_7)\n",
    "mse_8 = mean_squared_error(y_8_test, y_pred_8)\n",
    "\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "r_squared_3 = r2_score(y_3_test, y_pred_3)\n",
    "r_squared_5 = r2_score(y_5_test, y_pred_5)\n",
    "r_squared_4 = r2_score(y_4_test, y_pred_4)\n",
    "r_squared_2 = r2_score(y_2_test, y_pred_2)\n",
    "r_squared_6 = r2_score(y_6_test, y_pred_6)\n",
    "r_squared_7 = r2_score(y_7_test, y_pred_7)\n",
    "r_squared_8 = r2_score(y_8_test, y_pred_8)\n",
    "\n",
    "print('MSE 1: ',mse,'| R^2 1: ',r_squared)\n",
    "print('MSE 2: ',mse_2,'  | R^2 2: ',r_squared_2)\n",
    "print('MSE 3: ',mse_3,'| R^2 3: ',r_squared_3)\n",
    "print('MSE 4: ',mse_4,'| R^2 4: ',r_squared_4)\n",
    "print('MSE 5: ',mse_5,' | R^2 5: ',r_squared_5)\n",
    "print('MSE 6: ',mse_6,' | R^2 6: ',r_squared_6)\n",
    "print('MSE 7: ',mse_7,'| R^2 7: ',r_squared_7)\n",
    "print('MSE 8: ',mse_8,' | R^2 8: ',r_squared_8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac7dfc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = RidgeRegression(reg_param=1.5)\n",
    "scores = ['r2' , 'neg_mean_squared_error']\n",
    "\n",
    "cv_acc = cross_validate(model, X_2, y_2, cv=5, scoring=scores)\n",
    "r_squared_2 = r2_score(y_2_test, y_pred_2)\n",
    "print('[2] r2 Max:   ',cv_acc['test_r2'].max(), '\\t mse Min:  ',-cv_acc['test_neg_mean_squared_error'].max())\n",
    "print('[2] r2 Min:  ',cv_acc['test_r2'].min(), '\\t mse Min:  ',-cv_acc['test_neg_mean_squared_error'].min())\n",
    "print('[2] r2 Mean: ',cv_acc['test_r2'].mean(),'\\t mse Mean: ',-cv_acc['test_neg_mean_squared_error'].mean())\n",
    "print('R^2 2:\\t      ',r_squared_2,'\\t    MSE  : ',mse_2)\n",
    "print('--------------------------------------------------------------------')\n",
    "\n",
    "cv_acc = cross_validate(model, X_4, y_4, cv=5, scoring=scores)\n",
    "r_squared_4 = r2_score(y_4_test, y_pred_4)\n",
    "print('[4] r2 Max:   ',cv_acc['test_r2'].max(), '\\t mse Min:  ',-cv_acc['test_neg_mean_squared_error'].max())\n",
    "print('[4] r2 Min:  ',cv_acc['test_r2'].min(), '\\t mse Min:  ',-cv_acc['test_neg_mean_squared_error'].min())\n",
    "print('[4] r2 Mean: ',cv_acc['test_r2'].mean(),'\\t mse Mean: ',-cv_acc['test_neg_mean_squared_error'].mean())\n",
    "print('R^2 4:\\t      ',r_squared_4,'\\t    MSE  : ',mse_4)\n",
    "print('--------------------------------------------------------------------')\n",
    "\n",
    "cv_acc = cross_validate(model, X_6, y_6, cv=5, scoring=scores)\n",
    "r_squared_6 = r2_score(y_6_test, y_pred_6)\n",
    "print('[6] r2 Max:   ',cv_acc['test_r2'].max(), '\\t mse Min:  ',-cv_acc['test_neg_mean_squared_error'].max())\n",
    "print('[6] r2 Min:  ',cv_acc['test_r2'].min(), '\\t mse Min:  ',-cv_acc['test_neg_mean_squared_error'].min())\n",
    "print('[6] r2 Mean: ',cv_acc['test_r2'].mean(),'\\t mse Mean: ',-cv_acc['test_neg_mean_squared_error'].mean())\n",
    "print('R^2 6:\\t      ',r_squared_6,'\\t    MSE  : ',mse_6)\n",
    "print('--------------------------------------------------------------------')\n",
    "\n",
    "cv_acc = cross_validate(model, X_8, y_8, cv=5, scoring=scores)\n",
    "r_squared_8 = r2_score(y_8_test, y_pred_8)\n",
    "print('[8] r2 Max:   ',cv_acc['test_r2'].max(), '\\t mse Min:  ',-cv_acc['test_neg_mean_squared_error'].max())\n",
    "print('[8] r2 Min:  ',cv_acc['test_r2'].min(), '\\t mse Min:  ',-cv_acc['test_neg_mean_squared_error'].min())\n",
    "print('[8] r2 Mean: ',cv_acc['test_r2'].mean(),'\\t mse Mean: ',-cv_acc['test_neg_mean_squared_error'].mean())\n",
    "print('R^2 8:\\t      ',r_squared_8,'\\t    MSE  : ',mse_8)\n",
    "print('--------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2165025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT the dataset into train and test sets (70% train, 30% test) \n",
    "X_Test, X_Val, y_Test, y_Val = train_test_split(X, y, test_size=0.50, random_state=42)\n",
    "X_2_Test, X_2_Val, y_2_Test, y_2_Val = train_test_split(X_2, y_2, test_size=0.50, random_state=42)\n",
    "X_3_Test, X_3_Val, y_3_Test, y_3_Val = train_test_split(X_3, y_3, test_size=0.50, random_state=42)\n",
    "X_4_Test, X_4_Val, y_4_Test, y_4_Val = train_test_split(X_4, y_4, test_size=0.50, random_state=42)\n",
    "X_5_Test, X_5_Val, y_5_Test, y_5_Val = train_test_split(X_5, y_5, test_size=0.50, random_state=42)\n",
    "X_6_Test, X_6_Val, y_6_Test, y_6_Val = train_test_split(X_6, y_6, test_size=0.50, random_state=42)\n",
    "X_7_Test, X_7_Val, y_7_Test, y_7_Val = train_test_split(X_7, y_7, test_size=0.50, random_state=42)\n",
    "X_8_Test, X_8_Val, y_8_Test, y_8_Val = train_test_split(X_8, y_8, test_size=0.50, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1475b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Define a logarithmic range of values for the regularization parameter \n",
    "vec = np.exp(np.linspace(np.log(0.001), np.log(10), 50))\n",
    "alphas = np.insert(vec,0,[0.0]) # inserting also 0 to see if linear regression\n",
    "alphas = vec\n",
    "mse_val_2 = []\n",
    "mse_val_4 = []\n",
    "mse_val_6 = []\n",
    "mse_val_8 = []\n",
    "\n",
    "# Iterate over each value of alpha\n",
    "for alpha in alphas:\n",
    "    # Create and fit the ridge regression model\n",
    "    model = RidgeRegression(reg_param=alpha)\n",
    "   \n",
    "    # Fit thr model on train set\n",
    "    model.fit(X_2_train, y_2_train)\n",
    "    # Evaluate the model's performance using MSE\n",
    "    mse_val_2.append(mean_squared_error(y_2_Val, model.predict(X_2_Val)))\n",
    "\n",
    "    model.fit(X_4_train, y_4_train)\n",
    "    mse_val_4.append(mean_squared_error(y_4_Val, model.predict(X_4_Val)))\n",
    "\n",
    "    model.fit(X_6_train, y_6_train)\n",
    "    mse_val_6.append(mean_squared_error(y_6_Val, model.predict(X_6_Val)))\n",
    "\n",
    "    model.fit(X_8_train, y_8_train)\n",
    "    mse_val_8.append(mean_squared_error(y_8_Val, model.predict(X_8_Val)))\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20,10))    \n",
    "\n",
    "axs[0, 0].plot(alphas, mse_val_2, label='Validation MSE', color='green')\n",
    "axs[0, 0].set_title('Mean Squared Error vs. Alpha for Ridge Regression, 2nd case')\n",
    "axs[0, 0].set_xscale('log')\n",
    "axs[0, 1].plot(alphas, mse_val_4, label='Validation MSE', color='green')\n",
    "axs[0, 1].set_title('Mean Squared Error vs. Alpha for Ridge Regression, 4th case')\n",
    "axs[0, 1].set_xscale('log')\n",
    "axs[1, 0].plot(alphas, mse_val_6, label='Validation MSE', color='green')\n",
    "axs[1, 0].set_title('Mean Squared Error vs. Alpha for Ridge Regression, 6th case')\n",
    "axs[1, 0].set_xscale('log')\n",
    "axs[1, 1].plot(alphas, mse_val_8, label='Validation MSE', color='green')\n",
    "axs[1, 1].set_title('Mean Squared Error vs. Alpha for Ridge Regression, 8th case')\n",
    "axs[1, 1].set_xscale('log')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Regularization parameter', ylabel='Mean Squared Error (MSE)')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICTIONARIES with features as keys and correspondent regression coefficient as item\n",
    "my_dict_1 = dict(zip(numeric_df_aggr.drop('popularity',axis = 1).columns.append(pd.Index(['intercept'])), betas_1))\n",
    "sorted_dict_1 = sorted(my_dict_1.items(), key=lambda item: item[1], reverse=True)\n",
    "my_dict_2 = dict(zip(numeric_df_aggr.drop('popularity',axis = 1).columns, betas_2))\n",
    "sorted_dict_2 = sorted(my_dict_2.items(), key=lambda item: item[1], reverse=True)\n",
    "my_dict_3 = dict(zip(genre_df.drop('popularity',axis = 1).columns.append(pd.Index(['intercept'])), betas_3))\n",
    "sorted_dict_3 = sorted(my_dict_3.items(), key=lambda item: item[1], reverse=True)\n",
    "my_dict_4 = dict(zip(genre_df_aggr.drop('popularity',axis = 1).columns.append(pd.Index(['intercept'])), betas_4))\n",
    "sorted_dict_4 = sorted(my_dict_4.items(), key=lambda item: item[1], reverse=True)\n",
    "my_dict_6 = dict(zip(KT_df_aggr.columns, betas_6))\n",
    "sorted_dict_6 = sorted(my_dict_6.items(), key=lambda item: item[1], reverse=True)\n",
    "my_dict_8 = dict(zip(K_df_aggr.columns, betas_8))\n",
    "sorted_dict_8 = sorted(my_dict_8.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "sorted_dict_1 = dict(sorted_dict_1)\n",
    "sorted_dict_2 = dict(sorted_dict_2)\n",
    "sorted_dict_3 = dict(sorted_dict_3)\n",
    "sorted_dict_4 = dict(sorted_dict_4)\n",
    "sorted_dict_6 = dict(sorted_dict_6)\n",
    "sorted_dict_8 = dict(sorted_dict_8)\n",
    "\n",
    "\n",
    "#sorted_dict_1\n",
    "sorted_dict_2\n",
    "#sorted_dict_3\n",
    "#sorted_dict_4\n",
    "#sorted_dict_6\n",
    "#sorted_dict_8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE 1: ',mse,'| R^2 1: ',r_squared)\n",
    "print('MSE 2: ',mse_2,'  | R^2 2: ',r_squared_2)\n",
    "print('MSE 3: ',mse_3,'| R^2 3: ',r_squared_3)\n",
    "print('MSE 4: ',mse_4,'| R^2 4: ',r_squared_4)\n",
    "print('MSE 5: ',mse_5,' | R^2 5: ',r_squared_5)\n",
    "print('MSE 6: ',mse_6,' | R^2 6: ',r_squared_6)\n",
    "print('MSE 7: ',mse_7,'| R^2 7: ',r_squared_7)\n",
    "print('MSE 8: ',mse_8,' | R^2 8: ',r_squared_8)\n"
   ]
  },{
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ae64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_6_train, y_6_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d863a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_8_train, y_8_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
